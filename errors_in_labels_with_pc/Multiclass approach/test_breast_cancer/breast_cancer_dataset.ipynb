{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste de erros em rótulos usando o dataset breast_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedimento: Provocar erros propositais nos rótulos do dataset breast_c do sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from ocpc_py import MultiClassPC\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from cleanlab import Datalab\n",
    "from utils.confident_learning import get_CL_label_correction\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando o dataset e modificando os rótulos para induzir erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Importando os dados do dataset\n",
    "breast_c = load_breast_cancer()\n",
    "X = breast_c.data # Features\n",
    "Y_original = breast_c.target # Rótulos\n",
    "\n",
    "def plot_scatter(labels: list, X=X):\n",
    "    _, ax = plt.subplots()\n",
    "    scatter = ax.scatter(X[:,0], X[:,1], c=labels)\n",
    "    ax.set(xlabel=breast_c.feature_names[0], ylabel=breast_c.feature_names[1])\n",
    "    _ = ax.legend(\n",
    "        scatter.legend_elements()[0], breast_c.target_names, loc=\"lower right\", title=\"Classes\"\n",
    "    )\n",
    "    \n",
    "# Fazer o plot dos dados originais\n",
    "plot_scatter(labels=Y_original)\n",
    "\n",
    "# Alterando os dados de Y para causar erros propositais\n",
    "def alterar_rotulos(Y, percentual, random_state=None):\n",
    "    np.random.seed(random_state)  # Para reprodutibilidade\n",
    "    Y_alterado = Y.copy()\n",
    "    classes = np.unique(Y)\n",
    "\n",
    "    for classe in classes:\n",
    "        indices_classe = np.where(Y == classe)[0]  # Obtém índices da classe\n",
    "        n_alterar = int(len(indices_classe) * percentual)  # 40% dos índices\n",
    "        indices_escolhidos = np.random.choice(indices_classe, n_alterar, replace=False)\n",
    "\n",
    "        # Escolher novos rótulos aleatórios, diferentes do original\n",
    "        for idx in indices_escolhidos:\n",
    "            novas_classes = np.setdiff1d(classes, Y[idx])  # Evita o mesmo rótulo\n",
    "            Y_alterado[idx] = np.random.choice(novas_classes)\n",
    "\n",
    "    return Y_alterado\n",
    "\n",
    "Y_com_erro = alterar_rotulos(Y_original, 0.2)\n",
    "    \n",
    "# Fazer o plot dos dados alterados\n",
    "plot_scatter(labels=Y_com_erro)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando a correção de rótulos desenvolvida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "Y = Y_com_erro.copy()\n",
    "\n",
    "# # Rodando PCA nos dados\n",
    "# df_breast_c = pd.DataFrame(breast_c.data, columns=breast_c.feature_names) # Cria um dataframe com o dataset de breast_c\n",
    "\n",
    "# scaler = StandardScaler() # Scaler\n",
    "\n",
    "# breast_c_scaled = scaler.fit_transform(df_breast_c) # Normaliza os dados para serem usados dentro do PCA\n",
    "# df_breast_c_scaled = pd.DataFrame(breast_c_scaled, columns=breast_c.feature_names)\n",
    "\n",
    "# pca =  PCA(n_components=3) # Cria o objeto de pca com 2 componentes\n",
    "# pca.fit(breast_c_scaled) # Faz o PCA com a configuração correta\n",
    "\n",
    "# breast_c_pca = pca.transform(breast_c_scaled)\n",
    "\n",
    "# X_copy = X\n",
    "# X = breast_c_pca.data\n",
    "# Y = np.array(Y, dtype=int).ravel()\n",
    "\n",
    "clf = MultiClassPC(f=0.5)\n",
    "clf.fit(X, Y)\n",
    "\n",
    "curves_ = clf.curves\n",
    "\n",
    "# Calcula as distâncias de cada ponto à cada curva\n",
    "distancias = [curve.map_to_arcl(X) for curve in curves_]\n",
    "distances = {curve.class_label: curve.map_to_arcl(X) for curve in curves_}\n",
    "\n",
    "# Junta as informações das distâncias para obter, em cada índice de dados do treinamento as distâncias para cada ponto\n",
    "data_distances = pd.DataFrame({chave: dado[1] for chave, dado in distances.items()})\n",
    "data_distances[\"error_label\"] = Y\n",
    "# Para cada ponto é verificada qual a classe mais próxima e comparada com a classe indicada no início, caso exista algum erro de rótulo o código altera a label do dado para melhor ajustar os dados\n",
    "rows_to_adjust = []\n",
    "for i, row in data_distances.iterrows():\n",
    "    min_dist = row.iloc[:-1].idxmin()\n",
    "    # Classe cujo ponto tem menor distância\n",
    "    min_value = row.iloc[:-1].min()\n",
    "    if row[\"error_label\"] != min_dist:\n",
    "        rows_to_adjust.append(\n",
    "            {\n",
    "                \"index\": i,\n",
    "                \"error_label\": row[\"error_label\"],\n",
    "                \"fixed_label\": min_dist,\n",
    "                \"min_distance\": min_value,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Ajustando as labels\n",
    "for row in rows_to_adjust:\n",
    "    Y[row[\"index\"]] = row[\"fixed_label\"]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[Y.flatten() == 0][:, 0], X[Y.flatten() == 0][:, 1], color='purple', label='Classe 0 (ajustada)')\n",
    "ax.scatter(X[Y.flatten() == 1][:, 0], X[Y.flatten() == 1][:, 1], color='green', marker='*', label='Classe 1 (ajustada)')\n",
    "ax.scatter(X[Y.flatten() == 2][:, 0], X[Y.flatten() == 2][:, 1], color='yellow', marker='*', label='Classe 2 (ajustada)')\n",
    "\n",
    "# **Desenhando as curvas ajustadas**\n",
    "for curve in curves_:\n",
    "    curve.plot_curve(ax)\n",
    "\n",
    "avaliation = []\n",
    "for i in range(len(Y_original)):\n",
    "    avaliation.append(\n",
    "        {\n",
    "            \"original\": Y_original[i],\n",
    "            \"com_erro\": (\n",
    "                Y_com_erro[i],\n",
    "                \"Correto\" if Y_com_erro[i] == Y_original[i] else \"Errado\",\n",
    "            ),\n",
    "            \"corrigido\": (Y[i], \"Correto\" if Y[i] == Y_original[i] else \"Errado\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# Salva os dados ajustados em um novo DataFrame\n",
    "data_distances['original_label'] = Y_original\n",
    "data_distances[\"adjusted_label\"] = Y\n",
    "df_dados_ajustados = pd.DataFrame(\n",
    "    X, columns=[f\"Feature_{i+1}\" for i in range(X.shape[1])]\n",
    ")\n",
    "df_dados_ajustados[\"Label\"] = Y\n",
    "\n",
    "porcentagem_labels_erradas = (data_distances['error_label'] != data_distances['original_label']).mean()\n",
    "porcentagem_labels_erradas_depois_do_CL = (data_distances['adjusted_label'] != data_distances['original_label']).mean()\n",
    "score_correcao = porcentagem_labels_erradas - porcentagem_labels_erradas_depois_do_CL\n",
    "\n",
    "print(f'porcentagem_labels_erradas: {round(porcentagem_labels_erradas, 2)}%')\n",
    "print(f'porcentagem_labels_erradas_depois_do_CL: {round(porcentagem_labels_erradas_depois_do_CL, 2)}%')\n",
    "if score_correcao < 0:\n",
    "    print(f'Piora de : {round(score_correcao, 2)}%')\n",
    "elif score_correcao > 0:\n",
    "    print(f'Melhora de : {round(score_correcao, 2)}%')\n",
    "else:\n",
    "    print(f'Sem alteração: {round(score_correcao, 2)}%')\n",
    "    \n",
    "# Salvando no CSV\n",
    "# data_distances.to_excel(\"resultado_a_analizar.xlsx\", index=False)\n",
    "# df_dados_ajustados.to_excel(\"dados_ajustados.xlsx\", index=False)\n",
    "\n",
    "print(\"Resultados salvos no arquivo 'resultado_a_analizar.xlsx'.\")\n",
    "print(\"Dados ajustados salvos no arquivo 'dados_ajustados.csv'.\")\n",
    "\n",
    "# Comparação com o CL\n",
    "issues = get_CL_label_correction(X, Y_com_erro, Y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "Y = Y_com_erro.copy()\n",
    "\n",
    "# # Rodando PCA nos dados\n",
    "df_breast_c = pd.DataFrame(breast_c.data, columns=breast_c.feature_names) # Cria um dataframe com o dataset de breast_c\n",
    "\n",
    "scaler = StandardScaler() # Scaler\n",
    "\n",
    "breast_c_scaled = scaler.fit_transform(df_breast_c) # Normaliza os dados para serem usados dentro do PCA\n",
    "df_breast_c_scaled = pd.DataFrame(breast_c_scaled, columns=breast_c.feature_names)\n",
    "\n",
    "pca =  PCA(n_components=4) # Cria o objeto de pca com 2 componentes\n",
    "pca.fit(breast_c_scaled) # Faz o PCA com a configuração correta\n",
    "\n",
    "print(pca.explained_variance_ratio_\t)\n",
    "print(pca.explained_variance_)\n",
    "\n",
    "breast_c_pca = pca.transform(breast_c_scaled)\n",
    "\n",
    "clf = MultiClassPC(f=0.8, k_max=3, lamda=0.5, alfa=0.5)\n",
    "clf.fit(breast_c_pca, Y)\n",
    "\n",
    "curves_ = clf.curves\n",
    "\n",
    "# Calcula as distâncias de cada ponto à cada curva\n",
    "distancias = [curve.map_to_arcl(X) for curve in curves_]\n",
    "distances = {curve.class_label: curve.map_to_arcl(X) for curve in curves_}\n",
    "\n",
    "# Junta as informações das distâncias para obter, em cada índice de dados do treinamento as distâncias para cada ponto\n",
    "data_distances = pd.DataFrame({chave: dado[1] for chave, dado in distances.items()})\n",
    "data_distances[\"error_label\"] = Y\n",
    "# Para cada ponto é verificada qual a classe mais próxima e comparada com a classe indicada no início, caso exista algum erro de rótulo o código altera a label do dado para melhor ajustar os dados\n",
    "rows_to_adjust = []\n",
    "for i, row in data_distances.iterrows():\n",
    "    min_dist = row.iloc[:-1].idxmin()\n",
    "    # Classe cujo ponto tem menor distância\n",
    "    min_value = row.iloc[:-1].min()\n",
    "    if row[\"error_label\"] != min_dist:\n",
    "        rows_to_adjust.append(\n",
    "            {\n",
    "                \"index\": i,\n",
    "                \"error_label\": row[\"error_label\"],\n",
    "                \"fixed_label\": min_dist,\n",
    "                \"min_distance\": min_value,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Ajustando as labels\n",
    "for row in rows_to_adjust:\n",
    "    Y[row[\"index\"]] = row[\"fixed_label\"]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[Y.flatten() == 0][:, 0], X[Y.flatten() == 0][:, 1], color='purple', label='Classe 0 (ajustada)')\n",
    "ax.scatter(X[Y.flatten() == 1][:, 0], X[Y.flatten() == 1][:, 1], color='green', marker='*', label='Classe 1 (ajustada)')\n",
    "ax.scatter(X[Y.flatten() == 2][:, 0], X[Y.flatten() == 2][:, 1], color='yellow', marker='*', label='Classe 2 (ajustada)')\n",
    "\n",
    "# **Desenhando as curvas ajustadas**\n",
    "curves_[0].plot_curve(ax)\n",
    "curves_[1].plot_curve(ax)\n",
    "curves_[2].plot_curve(ax)\n",
    "\n",
    "avaliation = []\n",
    "for i in range(len(Y_original)):\n",
    "    avaliation.append(\n",
    "        {\n",
    "            \"original\": Y_original[i],\n",
    "            \"com_erro\": (\n",
    "                Y_com_erro[i],\n",
    "                \"Correto\" if Y_com_erro[i] == Y_original[i] else \"Errado\",\n",
    "            ),\n",
    "            \"corrigido\": (Y[i], \"Correto\" if Y[i] == Y_original[i] else \"Errado\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# Salva os dados ajustados em um novo DataFrame\n",
    "data_distances['original_label'] = Y_original\n",
    "data_distances[\"adjusted_label\"] = Y\n",
    "df_dados_ajustados = pd.DataFrame(\n",
    "    X, columns=[f\"Feature_{i+1}\" for i in range(X.shape[1])]\n",
    ")\n",
    "df_dados_ajustados[\"Label\"] = Y\n",
    "\n",
    "porcentagem_labels_erradas = (data_distances['error_label'] != data_distances['original_label']).mean()\n",
    "porcentagem_labels_erradas_depois_do_CL = (data_distances['adjusted_label'] != data_distances['original_label']).mean()\n",
    "score_correcao = porcentagem_labels_erradas - porcentagem_labels_erradas_depois_do_CL\n",
    "\n",
    "print(f'porcentagem_labels_erradas: {round(porcentagem_labels_erradas, 2)}%')\n",
    "print(f'porcentagem_labels_erradas_depois_do_CL: {round(porcentagem_labels_erradas_depois_do_CL, 2)}%')\n",
    "if score_correcao < 0:\n",
    "    print(f'Piora de : {round(score_correcao, 2)}%')\n",
    "elif score_correcao > 0:\n",
    "    print(f'Melhora de : {round(score_correcao, 2)}%')\n",
    "else:\n",
    "    print(f'Sem alteração: {round(score_correcao, 2)}%')\n",
    "    \n",
    "# Salvando no CSV\n",
    "# data_distances.to_excel(\"resultado_a_analizar.xlsx\", index=False)\n",
    "# df_dados_ajustados.to_excel(\"dados_ajustados.xlsx\", index=False)\n",
    "\n",
    "print(\"Resultados salvos no arquivo 'resultado_a_analizar.xlsx'.\")\n",
    "print(\"Dados ajustados salvos no arquivo 'dados_ajustados.csv'.\")\n",
    "\n",
    "# Comparação com o CL\n",
    "issues = get_CL_label_correction(X, Y_com_erro, Y_original)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
